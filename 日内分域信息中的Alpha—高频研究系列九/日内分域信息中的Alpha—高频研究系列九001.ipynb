{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这篇研报**《日内分域信息中的Alpha—高频研究系列九》**由兴证金工团队发布，重点聚焦日内分域信息对高频因子的影响及其构建过程。报告的核心在于通过对日内交易的时间、股价和成交量维度进行分域分析，构建多种Alpha因子，揭示出其中的选股能力和特异性。\n",
    "\n",
    "几个关键要点：\n",
    "\n",
    "1. **日内分域信息构建**：以时间、价格和交易活跃度三个维度对日内数据进行分域，通过这些特征来刻画Alpha信息。基础型因子构建基于开盘和尾盘量价差异，显示出良好的股价预测能力。\n",
    "   \n",
    "2. **显著性因子**：通过显著性理论，结合个股的量价特征，构建了自身显著性因子和“同伴”显著性因子。两者都表现出较高的预测能力，尤其是从股票间成对相关性角度构建的因子具备极强的特异性。\n",
    "\n",
    "3. **因子表现**：无论是基础型因子还是显著性因子，多空组合测试的夏普比率都大于3，部分因子的多空收益率接近35%，表现出较为显著的Alpha捕捉能力。\n",
    "\n",
    "4. **风险提示**：该模型基于历史数据，市场环境变化时可能失效，建议投资者审慎考虑该模型在不同市场环境下的表现。\n",
    "\n",
    "这份报告提供了有关如何基于分域信息从日内数据中挖掘Alpha的详细方法，适用于高频量化策略的开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要复现这份研报的框架，我们可以分成几个关键部分：数据处理、因子构建、回测分析、风险提示等。以下是一个完整的框架，其中每个部分都对应研报中的相应模块。\n",
    "\n",
    "1. 数据准备与预处理\n",
    "\n",
    "首先要处理分钟级别的高频数据，这些数据将用来构建因子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/zhangrui/opt/anaconda3/envs/suishi/lib/python3.8/site-packages (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/zhangrui/opt/anaconda3/envs/suishi/lib/python3.8/site-packages (from pyarrow) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 指定包含Feather文件的目录路径\n",
    "directory_path = '/Users/zhangrui/Desktop/励京资本/A股分钟'\n",
    "\n",
    "# 获取目录下所有.feather文件\n",
    "file_paths = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.feather')]\n",
    "\n",
    "# 读取数据并整合\n",
    "all_data = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # 读取每个feather文件\n",
    "    df = pd.read_feather(file_path)\n",
    "    all_data.append(df)\n",
    "\n",
    "# 将所有数据拼接成一个完整的DataFrame\n",
    "data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 数据预处理：处理缺失值、去噪声等\n",
    "data['volume'].fillna(0, inplace=True)\n",
    "data['close'].fillna(method='ffill', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 09:31:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.32</td>\n",
       "      <td>75.8</td>\n",
       "      <td>76.25</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>1972620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 09:32:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.25</td>\n",
       "      <td>75.95</td>\n",
       "      <td>75.95</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>435038.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 09:33:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.1</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.02</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>590132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 09:34:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.17</td>\n",
       "      <td>75.95</td>\n",
       "      <td>76.1</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>844782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 09:35:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.32</td>\n",
       "      <td>76.54</td>\n",
       "      <td>76.17</td>\n",
       "      <td>76.54</td>\n",
       "      <td>15324.0</td>\n",
       "      <td>1170280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008235</th>\n",
       "      <td>2024-08-22 14:56:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>497302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008236</th>\n",
       "      <td>2024-08-22 14:57:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>452122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008237</th>\n",
       "      <td>2024-08-22 14:58:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>112.0</td>\n",
       "      <td>22407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008238</th>\n",
       "      <td>2024-08-22 14:59:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008239</th>\n",
       "      <td>2024-08-22 15:00:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>2039240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date        stkcd    open    high     low   close  \\\n",
       "0        2022-12-01 09:31:00  000004.XSHE   75.87   76.32    75.8   76.25   \n",
       "1        2022-12-01 09:32:00  000004.XSHE   76.25   76.25   75.95   75.95   \n",
       "2        2022-12-01 09:33:00  000004.XSHE    76.1    76.1   75.87   76.02   \n",
       "3        2022-12-01 09:34:00  000004.XSHE   76.02   76.17   75.95    76.1   \n",
       "4        2022-12-01 09:35:00  000004.XSHE   76.32   76.54   76.17   76.54   \n",
       "...                      ...          ...     ...     ...     ...     ...   \n",
       "1008235  2024-08-22 14:56:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008236  2024-08-22 14:57:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008237  2024-08-22 14:58:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008238  2024-08-22 14:59:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008239  2024-08-22 15:00:00  000006.XSHE  199.33  199.33  199.33  199.33   \n",
       "\n",
       "          volume      money  \n",
       "0        25947.0  1972620.0  \n",
       "1         5721.0   435038.0  \n",
       "2         7763.0   590132.0  \n",
       "3        11107.0   844782.0  \n",
       "4        15324.0  1170280.0  \n",
       "...          ...        ...  \n",
       "1008235   2492.0   497302.0  \n",
       "1008236   2266.0   452122.0  \n",
       "1008237    112.0    22407.0  \n",
       "1008238      0.0        0.0  \n",
       "1008239  10231.0  2039240.0  \n",
       "\n",
       "[1008240 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分域数据准备，比如将数据按时间段分域\n",
    "# Convert 'date' to a datetime object\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Define morning and afternoon sessions\n",
    "def segment_trading_session(row):\n",
    "    hour = row['date'].hour\n",
    "    minute = row['date'].minute\n",
    "    if hour < 12:\n",
    "        return 'morning'\n",
    "    else:\n",
    "        return 'afternoon'\n",
    "\n",
    "# Apply the session segmentation\n",
    "data['session'] = data.apply(segment_trading_session, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 09:31:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.32</td>\n",
       "      <td>75.8</td>\n",
       "      <td>76.25</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>1972620.0</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 09:32:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.25</td>\n",
       "      <td>75.95</td>\n",
       "      <td>75.95</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>435038.0</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 09:33:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.1</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.02</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>590132.0</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 09:34:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.17</td>\n",
       "      <td>75.95</td>\n",
       "      <td>76.1</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>844782.0</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 09:35:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.32</td>\n",
       "      <td>76.54</td>\n",
       "      <td>76.17</td>\n",
       "      <td>76.54</td>\n",
       "      <td>15324.0</td>\n",
       "      <td>1170280.0</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008235</th>\n",
       "      <td>2024-08-22 14:56:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>497302.0</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008236</th>\n",
       "      <td>2024-08-22 14:57:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>452122.0</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008237</th>\n",
       "      <td>2024-08-22 14:58:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>112.0</td>\n",
       "      <td>22407.0</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008238</th>\n",
       "      <td>2024-08-22 14:59:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008239</th>\n",
       "      <td>2024-08-22 15:00:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>2039240.0</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date        stkcd    open    high     low   close  \\\n",
       "0       2022-12-01 09:31:00  000004.XSHE   75.87   76.32    75.8   76.25   \n",
       "1       2022-12-01 09:32:00  000004.XSHE   76.25   76.25   75.95   75.95   \n",
       "2       2022-12-01 09:33:00  000004.XSHE    76.1    76.1   75.87   76.02   \n",
       "3       2022-12-01 09:34:00  000004.XSHE   76.02   76.17   75.95    76.1   \n",
       "4       2022-12-01 09:35:00  000004.XSHE   76.32   76.54   76.17   76.54   \n",
       "...                     ...          ...     ...     ...     ...     ...   \n",
       "1008235 2024-08-22 14:56:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008236 2024-08-22 14:57:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008237 2024-08-22 14:58:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008238 2024-08-22 14:59:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008239 2024-08-22 15:00:00  000006.XSHE  199.33  199.33  199.33  199.33   \n",
       "\n",
       "          volume      money    session  \n",
       "0        25947.0  1972620.0    morning  \n",
       "1         5721.0   435038.0    morning  \n",
       "2         7763.0   590132.0    morning  \n",
       "3        11107.0   844782.0    morning  \n",
       "4        15324.0  1170280.0    morning  \n",
       "...          ...        ...        ...  \n",
       "1008235   2492.0   497302.0  afternoon  \n",
       "1008236   2266.0   452122.0  afternoon  \n",
       "1008237    112.0    22407.0  afternoon  \n",
       "1008238      0.0        0.0  afternoon  \n",
       "1008239  10231.0  2039240.0  afternoon  \n",
       "\n",
       "[1008240 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour from the 'date' column for segmentation\n",
    "data['hour'] = data['date'].dt.hour\n",
    "\n",
    "# Define hourly segments (e.g., 9:30-10:30, 10:30-11:30, etc.)\n",
    "def hourly_segment(row):\n",
    "    hour = row['hour']\n",
    "    if hour == 9:\n",
    "        return '9:30-10:30'\n",
    "    elif hour == 10:\n",
    "        return '10:30-11:30'\n",
    "    elif hour == 11:\n",
    "        return '11:30-12:30'\n",
    "    elif hour == 13:\n",
    "        return '13:00-14:00'\n",
    "    else:\n",
    "        return '14:00-15:00'\n",
    "\n",
    "# Apply the hourly segmentation\n",
    "data['hour_segment'] = data.apply(hourly_segment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>session</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 09:31:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.32</td>\n",
       "      <td>75.8</td>\n",
       "      <td>76.25</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>1972620.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 09:32:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.25</td>\n",
       "      <td>75.95</td>\n",
       "      <td>75.95</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>435038.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 09:33:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.1</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.02</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>590132.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 09:34:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.17</td>\n",
       "      <td>75.95</td>\n",
       "      <td>76.1</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>844782.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 09:35:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.32</td>\n",
       "      <td>76.54</td>\n",
       "      <td>76.17</td>\n",
       "      <td>76.54</td>\n",
       "      <td>15324.0</td>\n",
       "      <td>1170280.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008235</th>\n",
       "      <td>2024-08-22 14:56:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>497302.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008236</th>\n",
       "      <td>2024-08-22 14:57:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>452122.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008237</th>\n",
       "      <td>2024-08-22 14:58:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>112.0</td>\n",
       "      <td>22407.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008238</th>\n",
       "      <td>2024-08-22 14:59:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008239</th>\n",
       "      <td>2024-08-22 15:00:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>2039240.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>15</td>\n",
       "      <td>14:00-15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date        stkcd    open    high     low   close  \\\n",
       "0       2022-12-01 09:31:00  000004.XSHE   75.87   76.32    75.8   76.25   \n",
       "1       2022-12-01 09:32:00  000004.XSHE   76.25   76.25   75.95   75.95   \n",
       "2       2022-12-01 09:33:00  000004.XSHE    76.1    76.1   75.87   76.02   \n",
       "3       2022-12-01 09:34:00  000004.XSHE   76.02   76.17   75.95    76.1   \n",
       "4       2022-12-01 09:35:00  000004.XSHE   76.32   76.54   76.17   76.54   \n",
       "...                     ...          ...     ...     ...     ...     ...   \n",
       "1008235 2024-08-22 14:56:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008236 2024-08-22 14:57:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008237 2024-08-22 14:58:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008238 2024-08-22 14:59:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008239 2024-08-22 15:00:00  000006.XSHE  199.33  199.33  199.33  199.33   \n",
       "\n",
       "          volume      money    session  hour hour_segment  \n",
       "0        25947.0  1972620.0    morning     9   9:30-10:30  \n",
       "1         5721.0   435038.0    morning     9   9:30-10:30  \n",
       "2         7763.0   590132.0    morning     9   9:30-10:30  \n",
       "3        11107.0   844782.0    morning     9   9:30-10:30  \n",
       "4        15324.0  1170280.0    morning     9   9:30-10:30  \n",
       "...          ...        ...        ...   ...          ...  \n",
       "1008235   2492.0   497302.0  afternoon    14  14:00-15:00  \n",
       "1008236   2266.0   452122.0  afternoon    14  14:00-15:00  \n",
       "1008237    112.0    22407.0  afternoon    14  14:00-15:00  \n",
       "1008238      0.0        0.0  afternoon    14  14:00-15:00  \n",
       "1008239  10231.0  2039240.0  afternoon    15  14:00-15:00  \n",
       "\n",
       "[1008240 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate session or hourly price difference (open-close diff for each segment)\n",
    "def calc_segment_price_diff(df):\n",
    "    open_price = df.iloc[0]['open']\n",
    "    close_price = df.iloc[-1]['close']\n",
    "    return close_price - open_price\n",
    "\n",
    "# Group by 'stkcd' and 'session' or 'hour_segment' and calculate the open-close difference for each group\n",
    "price_diff = data.groupby(['stkcd', 'session']).apply(calc_segment_price_diff)\n",
    "\n",
    "# Convert the result to a DataFrame and reset the index so it aligns with the original data\n",
    "price_diff = price_diff.reset_index(name='price_diff')\n",
    "\n",
    "# Merge the calculated 'price_diff' back into the original DataFrame\n",
    "data = pd.merge(data, price_diff, on=['stkcd', 'session'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>session</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_segment</th>\n",
       "      <th>price_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 09:31:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.32</td>\n",
       "      <td>75.8</td>\n",
       "      <td>76.25</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>1972620.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 09:32:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.25</td>\n",
       "      <td>75.95</td>\n",
       "      <td>75.95</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>435038.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 09:33:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.1</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.02</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>590132.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 09:34:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.17</td>\n",
       "      <td>75.95</td>\n",
       "      <td>76.1</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>844782.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 09:35:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.32</td>\n",
       "      <td>76.54</td>\n",
       "      <td>76.17</td>\n",
       "      <td>76.54</td>\n",
       "      <td>15324.0</td>\n",
       "      <td>1170280.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008235</th>\n",
       "      <td>2024-08-22 14:56:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>497302.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008236</th>\n",
       "      <td>2024-08-22 14:57:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>452122.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008237</th>\n",
       "      <td>2024-08-22 14:58:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>112.0</td>\n",
       "      <td>22407.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008238</th>\n",
       "      <td>2024-08-22 14:59:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008239</th>\n",
       "      <td>2024-08-22 15:00:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>2039240.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>15</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date        stkcd    open    high     low   close  \\\n",
       "0       2022-12-01 09:31:00  000004.XSHE   75.87   76.32    75.8   76.25   \n",
       "1       2022-12-01 09:32:00  000004.XSHE   76.25   76.25   75.95   75.95   \n",
       "2       2022-12-01 09:33:00  000004.XSHE    76.1    76.1   75.87   76.02   \n",
       "3       2022-12-01 09:34:00  000004.XSHE   76.02   76.17   75.95    76.1   \n",
       "4       2022-12-01 09:35:00  000004.XSHE   76.32   76.54   76.17   76.54   \n",
       "...                     ...          ...     ...     ...     ...     ...   \n",
       "1008235 2024-08-22 14:56:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008236 2024-08-22 14:57:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008237 2024-08-22 14:58:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008238 2024-08-22 14:59:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008239 2024-08-22 15:00:00  000006.XSHE  199.33  199.33  199.33  199.33   \n",
       "\n",
       "          volume      money    session  hour hour_segment price_diff  \n",
       "0        25947.0  1972620.0    morning     9   9:30-10:30       3.21  \n",
       "1         5721.0   435038.0    morning     9   9:30-10:30       3.21  \n",
       "2         7763.0   590132.0    morning     9   9:30-10:30       3.21  \n",
       "3        11107.0   844782.0    morning     9   9:30-10:30       3.21  \n",
       "4        15324.0  1170280.0    morning     9   9:30-10:30       3.21  \n",
       "...          ...        ...        ...   ...          ...        ...  \n",
       "1008235   2492.0   497302.0  afternoon    14  14:00-15:00    -125.52  \n",
       "1008236   2266.0   452122.0  afternoon    14  14:00-15:00    -125.52  \n",
       "1008237    112.0    22407.0  afternoon    14  14:00-15:00    -125.52  \n",
       "1008238      0.0        0.0  afternoon    14  14:00-15:00    -125.52  \n",
       "1008239  10231.0  2039240.0  afternoon    15  14:00-15:00    -125.52  \n",
       "\n",
       "[1008240 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame, save it to your desktop\n",
    "save_path = '/Users/zhangrui/Desktop/data_modified001.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "data.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>session</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>high_rank</th>\n",
       "      <th>low_rank</th>\n",
       "      <th>highRank_sum</th>\n",
       "      <th>lowRank_sum</th>\n",
       "      <th>high_dt</th>\n",
       "      <th>low_dt</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>diff_vol</th>\n",
       "      <th>future_return</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1657.91</td>\n",
       "      <td>1691.37</td>\n",
       "      <td>1656.67</td>\n",
       "      <td>1687.6500000000</td>\n",
       "      <td>160780.0</td>\n",
       "      <td>268431460.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>801120.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1657.91</td>\n",
       "      <td>1691.37</td>\n",
       "      <td>1656.67</td>\n",
       "      <td>1687.6500000000</td>\n",
       "      <td>160780.0</td>\n",
       "      <td>268431460.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>1.989583</td>\n",
       "      <td>1.956250</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0117500666607412674428939650</td>\n",
       "      <td>801120.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1685.17</td>\n",
       "      <td>1692.61</td>\n",
       "      <td>1666.59</td>\n",
       "      <td>1667.8200000000</td>\n",
       "      <td>65530.0</td>\n",
       "      <td>109918445.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>2.988542</td>\n",
       "      <td>2.953125</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>801120.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1685.17</td>\n",
       "      <td>1692.61</td>\n",
       "      <td>1666.59</td>\n",
       "      <td>1667.8200000000</td>\n",
       "      <td>65530.0</td>\n",
       "      <td>109918445.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>3.987500</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0007374896571572471849480160</td>\n",
       "      <td>801120.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1667.82</td>\n",
       "      <td>1670.30</td>\n",
       "      <td>1666.59</td>\n",
       "      <td>1666.5900000000</td>\n",
       "      <td>42739.0</td>\n",
       "      <td>71314814.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>4.978125</td>\n",
       "      <td>4.946875</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>801120.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008235</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>16979.0</td>\n",
       "      <td>379664.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608760.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008236</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>8756.0</td>\n",
       "      <td>196265.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608760.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008237</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608760.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008238</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00627</td>\n",
       "      <td>608760.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008239</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>94809.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>608760.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date        stkcd     open     high      low            close  \\\n",
       "0       2022-12-01  000001.XSHE  1657.91  1691.37  1656.67  1687.6500000000   \n",
       "1       2022-12-01  000001.XSHE  1657.91  1691.37  1656.67  1687.6500000000   \n",
       "2       2022-12-01  000001.XSHE  1685.17  1692.61  1666.59  1667.8200000000   \n",
       "3       2022-12-01  000001.XSHE  1685.17  1692.61  1666.59  1667.8200000000   \n",
       "4       2022-12-01  000001.XSHE  1667.82  1670.30  1666.59  1666.5900000000   \n",
       "...            ...          ...      ...      ...      ...              ...   \n",
       "1008235 2024-08-22  000010.XSHE    22.47    22.47    22.33            22.33   \n",
       "1008236 2024-08-22  000010.XSHE    22.47    22.47    22.33            22.33   \n",
       "1008237 2024-08-22  000010.XSHE    22.33    22.33    22.33            22.33   \n",
       "1008238 2024-08-22  000010.XSHE    22.33    22.33    22.33            22.33   \n",
       "1008239 2024-08-22  000010.XSHE    22.47    22.47    22.47            22.47   \n",
       "\n",
       "           volume                 money    session  hour  ... high_rank  \\\n",
       "0        160780.0  268431460.0000000000    morning     9  ...  0.994792   \n",
       "1        160780.0  268431460.0000000000    morning     9  ...  0.994792   \n",
       "2         65530.0  109918445.0000000000    morning     9  ...  0.998958   \n",
       "3         65530.0  109918445.0000000000    morning     9  ...  0.998958   \n",
       "4         42739.0   71314814.0000000000    morning     9  ...  0.990625   \n",
       "...           ...                   ...        ...   ...  ...       ...   \n",
       "1008235   16979.0              379664.0  afternoon    14  ...  0.120833   \n",
       "1008236    8756.0              196265.0  afternoon    14  ...  0.120833   \n",
       "1008237       0.0                   0.0  afternoon    14  ...  0.008333   \n",
       "1008238       0.0                   0.0  afternoon    14  ...  0.008333   \n",
       "1008239    4220.0               94809.0  afternoon    15  ...  0.120833   \n",
       "\n",
       "         low_rank highRank_sum lowRank_sum  high_dt  low_dt  diff_std  \\\n",
       "0        0.978125     0.994792    0.978125       14     477  0.044682   \n",
       "1        0.978125     1.989583    1.956250       14     477  0.044682   \n",
       "2        0.996875     2.988542    2.953125       14     477  0.044682   \n",
       "3        0.996875     3.987500    3.950000       14     477  0.044682   \n",
       "4        0.996875     4.978125    4.946875       14     477  0.044682   \n",
       "...           ...          ...         ...      ...     ...       ...   \n",
       "1008235  0.058333     1.812500    1.029167       33     231  0.029615   \n",
       "1008236  0.058333     1.812500    1.029167       33     231  0.029615   \n",
       "1008237  0.058333     1.700000    1.029167       33     231  0.029615   \n",
       "1008238  0.058333     1.587500    1.029167       33     231  0.029615   \n",
       "1008239  0.212500     1.587500    1.029167       33     231  0.029615   \n",
       "\n",
       "         diff_vol                    future_return      rank  \n",
       "0             0.0                                0  801120.5  \n",
       "1             0.0  -0.0117500666607412674428939650  801120.5  \n",
       "2             0.0                                0  801120.5  \n",
       "3             0.0  -0.0007374896571572471849480160  801120.5  \n",
       "4             0.0                                0  801120.5  \n",
       "...           ...                              ...       ...  \n",
       "1008235       0.0                              0.0  608760.5  \n",
       "1008236       0.0                              0.0  608760.5  \n",
       "1008237       0.0                              0.0  608760.5  \n",
       "1008238       0.0                          0.00627  608760.5  \n",
       "1008239       0.0                              NaN  608760.5  \n",
       "\n",
       "[1008240 rows x 24 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Index' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Index' object is not callable"
     ]
    }
   ],
   "source": [
    "print(merged_data.columns())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 日内基础因子构建\n",
    "\n",
    "在这一部分，构建基础型因子，依照开盘、尾盘的量价差异等特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要构建三个基础型因子，分别是开盘和尾盘半小时之间的差异：\n",
    "\n",
    "\t1.\tlh_rtnDiff: 涨跌幅比值\n",
    "\t2.\tlh_volDiff: 成交量之和比值\n",
    "\t3.\tlh_stdDiff: 波动率比值\n",
    "\n",
    "下面是如何根据这些因子构建方法进行代码实现的步骤：\n",
    "\n",
    "1. 构建因子的代码\n",
    "\n",
    "首先，我们需要将每个交易日划分为开盘的前半小时和尾盘的后半小时。\n",
    "\n",
    "步骤：\n",
    "\n",
    "\t1.\t开盘前半小时： 9:30 至 10:00\n",
    "\t2.\t尾盘后半小时： 14:30 至 15:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [stkcd, date, lh_rtnDiff, lh_volDiff, lh_stdDiff]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 确保 'date' 列是时间格式\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# 定义开盘和尾盘半小时的时间范围\n",
    "def label_time_period(row):\n",
    "    hour, minute = row['date'].hour, row['date'].minute\n",
    "    if (hour == 9 and minute >= 30) or (hour == 10 and minute == 0):\n",
    "        return 'morning_half_hour'\n",
    "    elif (hour == 14 and minute >= 30) or (hour == 15 and minute == 0):\n",
    "        return 'afternoon_half_hour'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# 为每行数据打上时间段标签（开盘前半小时、尾盘后半小时等）\n",
    "data['time_period'] = data.apply(label_time_period, axis=1)\n",
    "\n",
    "# 将时间戳向下取整到分钟，确保时间一致性\n",
    "data['date'] = data['date'].dt.floor('T')\n",
    "\n",
    "# 分别计算开盘和尾盘半小时的聚合数据\n",
    "morning_data = data[data['time_period'] == 'morning_half_hour'].groupby(['stkcd', 'date']).agg({\n",
    "    'open': 'first',  # 开盘价\n",
    "    'close': 'last',  # 收盘价\n",
    "    'volume': 'sum',  # 成交量总和\n",
    "    'high': 'max',    # 最高价\n",
    "    'low': 'min'      # 最低价\n",
    "}).reset_index()\n",
    "\n",
    "afternoon_data = data[data['time_period'] == 'afternoon_half_hour'].groupby(['stkcd', 'date']).agg({\n",
    "    'open': 'first',  # 开盘价\n",
    "    'close': 'last',  # 收盘价\n",
    "    'volume': 'sum',  # 成交量总和\n",
    "    'high': 'max',    # 最高价\n",
    "    'low': 'min'      # 最低价\n",
    "}).reset_index()\n",
    "\n",
    "# 合并早盘和尾盘数据，确保它们能够正确匹配\n",
    "merged_data = pd.merge(morning_data, afternoon_data, on=['stkcd', 'date'], suffixes=('_morning', '_afternoon'))\n",
    "\n",
    "# 构建因子：\n",
    "# 1. lh_rtnDiff: 涨跌幅比值 = (尾盘收盘价 - 尾盘开盘价) / (开盘收盘价 - 开盘开盘价)\n",
    "merged_data['rtn_morning'] = (merged_data['close_morning'] - merged_data['open_morning']) / merged_data['open_morning']\n",
    "merged_data['rtn_afternoon'] = (merged_data['close_afternoon'] - merged_data['open_afternoon']) / merged_data['open_afternoon']\n",
    "\n",
    "# 使用 np.divide 处理除零问题\n",
    "merged_data['lh_rtnDiff'] = np.divide(merged_data['rtn_afternoon'], merged_data['rtn_morning'], where=merged_data['rtn_morning'] != 0)\n",
    "\n",
    "# 2. lh_volDiff: 成交量比值 = 尾盘成交量 / 开盘成交量\n",
    "merged_data['lh_volDiff'] = np.divide(merged_data['volume_afternoon'], merged_data['volume_morning'], where=merged_data['volume_morning'] != 0)\n",
    "\n",
    "# 3. lh_stdDiff: 波动率比值 = 尾盘波动率 / 开盘波动率\n",
    "merged_data['std_morning'] = (merged_data['high_morning'] - merged_data['low_morning']) / merged_data['open_morning']\n",
    "merged_data['std_afternoon'] = (merged_data['high_afternoon'] - merged_data['low_afternoon']) / merged_data['open_afternoon']\n",
    "\n",
    "merged_data['lh_stdDiff'] = np.divide(merged_data['std_afternoon'], merged_data['std_morning'], where=merged_data['std_morning'] != 0)\n",
    "\n",
    "# 最终输出因子数据\n",
    "factor_data = merged_data[['stkcd', 'date', 'lh_rtnDiff', 'lh_volDiff', 'lh_stdDiff']]\n",
    "\n",
    "# 显示前几行结果\n",
    "print(factor_data.head())\n",
    "\n",
    "# 如果需要保存结果到文件，例如Mac桌面：\n",
    "factor_data.to_csv('/Users/zhangrui/Desktop/factor_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stkcd        date                       lh_rtnDiff  \\\n",
      "0  000001.XSHE  2022-12-01   0.2260276338195973465050902702   \n",
      "1  000001.XSHE  2022-12-02  0.07802675724652283262577831569   \n",
      "2  000001.XSHE  2022-12-05                            0E+30   \n",
      "3  000001.XSHE  2022-12-06   0.4281048803387075540684722467   \n",
      "4  000001.XSHE  2022-12-07  -0.3176339952421322670229882376   \n",
      "\n",
      "                       lh_volDiff                       lh_stdDiff  \n",
      "0  0.2331566256245484503272496700   0.1536390853747409429132968358  \n",
      "1  0.1495969549662004764458196714  0.08825247980920375088080654777  \n",
      "2  0.5374809320472034614359515263   0.2105431795858279604178798930  \n",
      "3  0.2998128677179968576477686543   0.2576206359560364042181956882  \n",
      "4  0.7028859121652453430950039040   0.3560220018840977099504458495  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 确保 'date' 列是时间格式\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# 定义开盘和尾盘半小时的时间范围\n",
    "def label_time_period(row):\n",
    "    hour, minute = row['date'].hour, row['date'].minute\n",
    "    if (hour == 9 and minute >= 30) or (hour == 10 and minute == 0):\n",
    "        return 'morning_half_hour'\n",
    "    elif (hour == 14 and minute >= 30) or (hour == 15 and minute == 0):\n",
    "        return 'afternoon_half_hour'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# 为每行数据打上时间段标签（开盘前半小时、尾盘后半小时等）\n",
    "data['time_period'] = data.apply(label_time_period, axis=1)\n",
    "\n",
    "# 将时间戳向下取整到分钟，确保时间一致性\n",
    "data['date'] = data['date'].dt.floor('T')\n",
    "\n",
    "# 分别计算开盘和尾盘半小时的聚合数据\n",
    "morning_data = data[data['time_period'] == 'morning_half_hour'].groupby(['stkcd', data['date'].dt.date]).agg({\n",
    "    'open': 'first',  # 开盘价\n",
    "    'close': 'last',  # 收盘价\n",
    "    'volume': 'sum',  # 成交量总和\n",
    "    'high': 'max',    # 最高价\n",
    "    'low': 'min'      # 最低价\n",
    "}).reset_index()\n",
    "\n",
    "afternoon_data = data[data['time_period'] == 'afternoon_half_hour'].groupby(['stkcd', data['date'].dt.date]).agg({\n",
    "    'open': 'first',  # 开盘价\n",
    "    'close': 'last',  # 收盘价\n",
    "    'volume': 'sum',  # 成交量总和\n",
    "    'high': 'max',    # 最高价\n",
    "    'low': 'min'      # 最低价\n",
    "}).reset_index()\n",
    "\n",
    "# 合并早盘和尾盘数据，确保它们能够正确匹配\n",
    "merged_data = pd.merge(morning_data, afternoon_data, on=['stkcd', 'date'], suffixes=('_morning', '_afternoon'))\n",
    "\n",
    "# 构建因子：\n",
    "# 1. lh_rtnDiff: 涨跌幅比值 = (尾盘收盘价 - 尾盘开盘价) / (开盘收盘价 - 开盘开盘价)\n",
    "merged_data['rtn_morning'] = (merged_data['close_morning'] - merged_data['open_morning']) / merged_data['open_morning']\n",
    "merged_data['rtn_afternoon'] = (merged_data['close_afternoon'] - merged_data['open_afternoon']) / merged_data['open_afternoon']\n",
    "\n",
    "# 使用 np.divide 处理除零问题\n",
    "merged_data['lh_rtnDiff'] = np.divide(merged_data['rtn_afternoon'], merged_data['rtn_morning'], where=merged_data['rtn_morning'] != 0)\n",
    "\n",
    "# 2. lh_volDiff: 成交量比值 = 尾盘成交量 / 开盘成交量\n",
    "merged_data['lh_volDiff'] = np.divide(merged_data['volume_afternoon'], merged_data['volume_morning'], where=merged_data['volume_morning'] != 0)\n",
    "\n",
    "# 3. lh_stdDiff: 波动率比值 = 尾盘波动率 / 开盘波动率\n",
    "merged_data['std_morning'] = (merged_data['high_morning'] - merged_data['low_morning']) / merged_data['open_morning']\n",
    "merged_data['std_afternoon'] = (merged_data['high_afternoon'] - merged_data['low_afternoon']) / merged_data['open_afternoon']\n",
    "\n",
    "merged_data['lh_stdDiff'] = np.divide(merged_data['std_afternoon'], merged_data['std_morning'], where=merged_data['std_morning'] != 0)\n",
    "\n",
    "# 去掉含有NaN值的行\n",
    "factor_data = merged_data[['stkcd', 'date', 'lh_rtnDiff', 'lh_volDiff', 'lh_stdDiff']].dropna()\n",
    "\n",
    "# 显示前几行结果\n",
    "print(factor_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>session</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_segment</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>time_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 09:31:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.32</td>\n",
       "      <td>75.8</td>\n",
       "      <td>76.25</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>1972620.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>morning_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 09:32:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.25</td>\n",
       "      <td>75.95</td>\n",
       "      <td>75.95</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>435038.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>morning_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 09:33:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.1</td>\n",
       "      <td>76.1</td>\n",
       "      <td>75.87</td>\n",
       "      <td>76.02</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>590132.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>morning_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 09:34:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.17</td>\n",
       "      <td>75.95</td>\n",
       "      <td>76.1</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>844782.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>morning_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 09:35:00</td>\n",
       "      <td>000004.XSHE</td>\n",
       "      <td>76.32</td>\n",
       "      <td>76.54</td>\n",
       "      <td>76.17</td>\n",
       "      <td>76.54</td>\n",
       "      <td>15324.0</td>\n",
       "      <td>1170280.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>9:30-10:30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>morning_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008235</th>\n",
       "      <td>2024-08-22 14:56:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>497302.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008236</th>\n",
       "      <td>2024-08-22 14:57:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>452122.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008237</th>\n",
       "      <td>2024-08-22 14:58:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>112.0</td>\n",
       "      <td>22407.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008238</th>\n",
       "      <td>2024-08-22 14:59:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>199.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008239</th>\n",
       "      <td>2024-08-22 15:00:00</td>\n",
       "      <td>000006.XSHE</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>199.33</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>2039240.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>15</td>\n",
       "      <td>14:00-15:00</td>\n",
       "      <td>-125.52</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date        stkcd    open    high     low   close  \\\n",
       "0       2022-12-01 09:31:00  000004.XSHE   75.87   76.32    75.8   76.25   \n",
       "1       2022-12-01 09:32:00  000004.XSHE   76.25   76.25   75.95   75.95   \n",
       "2       2022-12-01 09:33:00  000004.XSHE    76.1    76.1   75.87   76.02   \n",
       "3       2022-12-01 09:34:00  000004.XSHE   76.02   76.17   75.95    76.1   \n",
       "4       2022-12-01 09:35:00  000004.XSHE   76.32   76.54   76.17   76.54   \n",
       "...                     ...          ...     ...     ...     ...     ...   \n",
       "1008235 2024-08-22 14:56:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008236 2024-08-22 14:57:00  000006.XSHE  199.33  199.84  199.33  199.33   \n",
       "1008237 2024-08-22 14:58:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008238 2024-08-22 14:59:00  000006.XSHE  199.84  199.84  199.84  199.84   \n",
       "1008239 2024-08-22 15:00:00  000006.XSHE  199.33  199.33  199.33  199.33   \n",
       "\n",
       "          volume      money    session  hour hour_segment price_diff  \\\n",
       "0        25947.0  1972620.0    morning     9   9:30-10:30       3.21   \n",
       "1         5721.0   435038.0    morning     9   9:30-10:30       3.21   \n",
       "2         7763.0   590132.0    morning     9   9:30-10:30       3.21   \n",
       "3        11107.0   844782.0    morning     9   9:30-10:30       3.21   \n",
       "4        15324.0  1170280.0    morning     9   9:30-10:30       3.21   \n",
       "...          ...        ...        ...   ...          ...        ...   \n",
       "1008235   2492.0   497302.0  afternoon    14  14:00-15:00    -125.52   \n",
       "1008236   2266.0   452122.0  afternoon    14  14:00-15:00    -125.52   \n",
       "1008237    112.0    22407.0  afternoon    14  14:00-15:00    -125.52   \n",
       "1008238      0.0        0.0  afternoon    14  14:00-15:00    -125.52   \n",
       "1008239  10231.0  2039240.0  afternoon    15  14:00-15:00    -125.52   \n",
       "\n",
       "                 time_period  \n",
       "0          morning_half_hour  \n",
       "1          morning_half_hour  \n",
       "2          morning_half_hour  \n",
       "3          morning_half_hour  \n",
       "4          morning_half_hour  \n",
       "...                      ...  \n",
       "1008235  afternoon_half_hour  \n",
       "1008236  afternoon_half_hour  \n",
       "1008237  afternoon_half_hour  \n",
       "1008238  afternoon_half_hour  \n",
       "1008239  afternoon_half_hour  \n",
       "\n",
       "[1008240 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 解释\n",
    "\n",
    "\t•\t时间段标签：我们首先对每一行数据进行标签化，标记其属于开盘前半小时或尾盘后半小时。\n",
    "\t•\t开盘和尾盘数据计算：分别对这两个时间段的交易数据进行聚合计算，得到每只股票在这两个时间段的开盘价、收盘价、最高价、最低价和成交量等信息。\n",
    "\t•\t因子计算：\n",
    "\t•\tlh_rtnDiff：基于开盘和尾盘的涨跌幅差异。\n",
    "\t•\tlh_volDiff：基于开盘和尾盘的成交量差异。\n",
    "\t•\tlh_stdDiff：基于开盘和尾盘的波动率差异。\n",
    "\n",
    "3. 保存结果\n",
    "\n",
    "最后将计算好的因子数据保存到文件中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果到Mac桌面\n",
    "factor_data.to_csv('/Users/zhangrui/Desktop/factor_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先我们需要构建 Rank IC 测试和组合回测，具体步骤如下：\n",
    "\n",
    "1. Rank IC 测试\n",
    "\n",
    "Rank IC 是指因子的值和未来收益率之间的秩相关系数（通常为 Spearman 相关系数），我们可以通过以下步骤计算因子的 Rank IC。\n",
    "\n",
    "2. 多空组合回测\n",
    "\n",
    "我们根据因子的值进行排序，构建多空组合（买入因子值高的股票，卖出因子值低的股票），并计算多空组合的收益率、夏普比率、年化波动率和最大回撤等指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh_rtnDiff IC: mean=nan, std=nan, ICIR=nan\n",
      "lh_volDiff IC: mean=nan, std=nan, ICIR=nan\n",
      "lh_stdDiff IC: mean=nan, std=nan, ICIR=nan\n",
      "lh_rtnDiff: 年化收益率=nan, 年化波动率=nan, 夏普比率=nan, 最大回撤=nan\n",
      "lh_volDiff: 年化收益率=nan, 年化波动率=nan, 夏普比率=nan, 最大回撤=nan\n",
      "lh_stdDiff: 年化收益率=nan, 年化波动率=nan, 夏普比率=nan, 最大回撤=nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# 使用现有的 data 计算收益率\n",
    "data['date'] = pd.to_datetime(data['date'])  # 确保 data 中的 'date' 列是 datetime 格式\n",
    "data = data.sort_values(['stkcd', 'date'])\n",
    "\n",
    "# 计算每日收益率 (Return)\n",
    "data['return'] = data.groupby('stkcd')['close'].pct_change()\n",
    "\n",
    "# 读取 factor_data 并确保 'date' 列为 datetime 类型\n",
    "factor_data['date'] = pd.to_datetime(factor_data['date'])  # 确保 factor_data 中的 'date' 列也是 datetime 格式\n",
    "\n",
    "# 合并因子数据（factor_data）和收益率数据（data）\n",
    "# 使用 'left' merge 方式以确保因子数据的完整性\n",
    "merged_data = pd.merge(factor_data, data[['stkcd', 'date', 'return']], on=['stkcd', 'date'], how='left')\n",
    "\n",
    "# 去掉合并后任何含有 NaN 值的行\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# Rank IC 测试\n",
    "def rank_ic(factor_col, return_col):\n",
    "    \"\"\"计算 Rank IC，即因子值与未来收益率的 Spearman 相关系数\"\"\"\n",
    "    ic_values = []\n",
    "    for date, group in merged_data.groupby('date'):\n",
    "        # 只在有超过1个数据点的情况下计算 Spearman 相关系数\n",
    "        if len(group) > 1:\n",
    "            ic_value, _ = spearmanr(group[factor_col], group[return_col])\n",
    "            ic_values.append(ic_value)\n",
    "    # 如果没有有效数据点，返回 NaN\n",
    "    if len(ic_values) == 0:\n",
    "        return np.nan, np.nan\n",
    "    return np.mean(ic_values), np.std(ic_values)\n",
    "\n",
    "# IC 计算\n",
    "ic_lh_rtnDiff_mean, ic_lh_rtnDiff_std = rank_ic('lh_rtnDiff', 'return')\n",
    "ic_lh_volDiff_mean, ic_lh_volDiff_std = rank_ic('lh_volDiff', 'return')\n",
    "ic_lh_stdDiff_mean, ic_lh_stdDiff_std = rank_ic('lh_stdDiff', 'return')\n",
    "\n",
    "# 计算 ICIR (IC mean / IC std)\n",
    "icir_lh_rtnDiff = ic_lh_rtnDiff_mean / ic_lh_rtnDiff_std if ic_lh_rtnDiff_std != 0 else np.nan\n",
    "icir_lh_volDiff = ic_lh_volDiff_mean / ic_lh_volDiff_std if ic_lh_volDiff_std != 0 else np.nan\n",
    "icir_lh_stdDiff = ic_lh_stdDiff_mean / ic_lh_stdDiff_std if ic_lh_stdDiff_std != 0 else np.nan\n",
    "\n",
    "# 显示结果\n",
    "print(f\"lh_rtnDiff IC: mean={ic_lh_rtnDiff_mean}, std={ic_lh_rtnDiff_std}, ICIR={icir_lh_rtnDiff}\")\n",
    "print(f\"lh_volDiff IC: mean={ic_lh_volDiff_mean}, std={ic_lh_volDiff_std}, ICIR={icir_lh_volDiff}\")\n",
    "print(f\"lh_stdDiff IC: mean={ic_lh_stdDiff_mean}, std={ic_lh_stdDiff_std}, ICIR={icir_lh_stdDiff}\")\n",
    "\n",
    "# 多空组合回测\n",
    "def long_short_test(factor_col):\n",
    "    \"\"\"多空组合回测，买入因子值最高的30%股票，卖出因子值最低的30%股票\"\"\"\n",
    "    results = []\n",
    "    for date, group in merged_data.groupby('date'):\n",
    "        # 确保分组内有足够的数据点\n",
    "        if len(group) > 1:\n",
    "            # 按因子值排序\n",
    "            group = group.sort_values(by=factor_col)\n",
    "            # 定义多头和空头组合\n",
    "            long_portfolio = group.iloc[-int(len(group)*0.3):]\n",
    "            short_portfolio = group.iloc[:int(len(group)*0.3)]\n",
    "            \n",
    "            # 计算多头、空头和多空组合收益率\n",
    "            long_return = long_portfolio['return'].mean()\n",
    "            short_return = short_portfolio['return'].mean()\n",
    "            long_short_return = long_return - short_return\n",
    "            \n",
    "            results.append(long_short_return)\n",
    "    \n",
    "    # 如果没有有效数据点，返回 NaN\n",
    "    if len(results) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    # 转换为 DataFrame 并计算年化收益率、波动率、夏普比率等指标\n",
    "    results_df = pd.DataFrame(results, columns=['long_short_return'])\n",
    "    annual_return = results_df['long_short_return'].mean() * 252\n",
    "    annual_volatility = results_df['long_short_return'].std() * np.sqrt(252)\n",
    "    sharpe_ratio = annual_return / annual_volatility if annual_volatility != 0 else np.nan\n",
    "    max_drawdown = results_df['long_short_return'].min()\n",
    "    \n",
    "    return annual_return, annual_volatility, sharpe_ratio, max_drawdown\n",
    "\n",
    "# 计算每个因子的多空组合表现\n",
    "annual_return_rtnDiff, annual_vol_rtnDiff, sharpe_rtnDiff, max_drawdown_rtnDiff = long_short_test('lh_rtnDiff')\n",
    "annual_return_volDiff, annual_vol_volDiff, sharpe_volDiff, max_drawdown_volDiff = long_short_test('lh_volDiff')\n",
    "annual_return_stdDiff, annual_vol_stdDiff, sharpe_stdDiff, max_drawdown_stdDiff = long_short_test('lh_stdDiff')\n",
    "\n",
    "# 显示多空组合测试结果\n",
    "print(f\"lh_rtnDiff: 年化收益率={annual_return_rtnDiff}, 年化波动率={annual_vol_rtnDiff}, 夏普比率={sharpe_rtnDiff}, 最大回撤={max_drawdown_rtnDiff}\")\n",
    "print(f\"lh_volDiff: 年化收益率={annual_return_volDiff}, 年化波动率={annual_vol_volDiff}, 夏普比率={sharpe_volDiff}, 最大回撤={max_drawdown_volDiff}\")\n",
    "print(f\"lh_stdDiff: 年化收益率={annual_return_stdDiff}, 年化波动率={annual_vol_stdDiff}, 夏普比率={sharpe_stdDiff}, 最大回撤={max_drawdown_stdDiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 中的 date 样本:\n",
      "705600    2022-12-01\n",
      "806400    2022-12-01\n",
      "705601    2022-12-01\n",
      "806401    2022-12-01\n",
      "705602    2022-12-01\n",
      "806402    2022-12-01\n",
      "705603    2022-12-01\n",
      "806403    2022-12-01\n",
      "705604    2022-12-01\n",
      "806404    2022-12-01\n",
      "Name: date, dtype: object\n",
      "Factor Data 中的 date 样本:\n",
      "0    2022-12-01\n",
      "1    2022-12-02\n",
      "2    2022-12-05\n",
      "3    2022-12-06\n",
      "4    2022-12-07\n",
      "5    2022-12-08\n",
      "6    2022-12-09\n",
      "7    2022-12-12\n",
      "8    2022-12-13\n",
      "9    2022-12-14\n",
      "Name: date, dtype: object\n",
      "Merged Data 分布:        lh_rtnDiff                      lh_volDiff lh_stdDiff  return\n",
      "count      883920                          883920     883920  883913\n",
      "unique       2499                            3289       3161   45716\n",
      "top         0E+30  0.2331566256245484503272496700      0E+29       0\n",
      "freq       195840                             480      23760  477441\n",
      "Merged Data 缺失值检查:\n",
      " stkcd         0\n",
      "date          0\n",
      "lh_rtnDiff    0\n",
      "lh_volDiff    0\n",
      "lh_stdDiff    0\n",
      "return        7\n",
      "dtype: int64\n",
      "Merged Data 样本:\n",
      "         stkcd        date                      lh_rtnDiff  \\\n",
      "0  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "1  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "2  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "3  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "4  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "5  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "6  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "7  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "8  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "9  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "\n",
      "                            return  \n",
      "0                              NaN  \n",
      "1                                0  \n",
      "2  -0.0117500666607412674428939650  \n",
      "3                                0  \n",
      "4  -0.0007374896571572471849480160  \n",
      "5                                0  \n",
      "6  -0.0022321026767231292639461415  \n",
      "7                                0  \n",
      "8  -0.0022370961049270237601255660  \n",
      "9                                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# 确保 'date' 列格式一致，保留日期部分\n",
    "data['date'] = pd.to_datetime(data['date']).dt.date  # 保留日期，不包括时间\n",
    "factor_data['date'] = pd.to_datetime(factor_data['date']).dt.date  # 确保格式一致\n",
    "\n",
    "# 检查 'date' 列的样本，确保格式一致\n",
    "print(\"Data 中的 date 样本:\")\n",
    "print(data['date'].head(10))\n",
    "print(\"Factor Data 中的 date 样本:\")\n",
    "print(factor_data['date'].head(10))\n",
    "\n",
    "# 合并因子数据（factor_data）和收益率数据（data）\n",
    "merged_data = pd.merge(factor_data, data[['stkcd', 'date', 'return']], on=['stkcd', 'date'], how='inner')\n",
    "\n",
    "# 检查合并后的数据分布\n",
    "print(\"Merged Data 分布:\", merged_data[['lh_rtnDiff', 'lh_volDiff', 'lh_stdDiff', 'return']].describe())\n",
    "\n",
    "# 检查是否有缺失值\n",
    "print(\"Merged Data 缺失值检查:\\n\", merged_data.isna().sum())\n",
    "\n",
    "# 检查合并数据的样本，确保 'date' 和 'stkcd' 对齐\n",
    "print(\"Merged Data 样本:\")\n",
    "print(merged_data[['stkcd', 'date', 'lh_rtnDiff', 'return']].head(10))\n",
    "\n",
    "# 去掉合并后任何含有 NaN 值的行\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# 后续步骤可以继续进行因子分析和回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data 缺失值检查:\n",
      " stkcd         0\n",
      "date          0\n",
      "lh_rtnDiff    0\n",
      "lh_volDiff    0\n",
      "lh_stdDiff    0\n",
      "return        0\n",
      "dtype: int64\n",
      "Merged Data 样本（处理后）:\n",
      "          stkcd        date                      lh_rtnDiff  \\\n",
      "1   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "2   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "3   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "4   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "5   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "6   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "7   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "8   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "9   000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "10  000001.XSHE  2022-12-01  0.2260276338195973465050902702   \n",
      "\n",
      "                             return  \n",
      "1                                 0  \n",
      "2   -0.0117500666607412674428939650  \n",
      "3                                 0  \n",
      "4   -0.0007374896571572471849480160  \n",
      "5                                 0  \n",
      "6   -0.0022321026767231292639461415  \n",
      "7                                 0  \n",
      "8   -0.0022370961049270237601255660  \n",
      "9                                 0  \n",
      "10  -0.0037308260253744387186209806  \n"
     ]
    }
   ],
   "source": [
    "# 删除 `return` 列中为 NaN 的行\n",
    "merged_data = merged_data.dropna(subset=['return'])\n",
    "\n",
    "# 再次检查是否存在 NaN 值\n",
    "print(\"Merged Data 缺失值检查:\\n\", merged_data.isna().sum())\n",
    "\n",
    "# 处理零收益率的情况，可以选择删除或保留\n",
    "# 如果希望删除零收益率的行（可选步骤），使用以下代码：\n",
    "# merged_data = merged_data[merged_data['return'] != 0]\n",
    "\n",
    "# 显示处理后的数据\n",
    "print(\"Merged Data 样本（处理后）:\")\n",
    "print(merged_data[['stkcd', 'date', 'lh_rtnDiff', 'return']].head(10))\n",
    "\n",
    "# 继续执行 Rank IC 测试和多空组合回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh_rtnDiff IC: mean=-1.2010783322195597e-05, std=0.016713078374647236, ICIR=-0.0007186457846338622\n",
      "lh_volDiff IC: mean=0.0015685578480131735, std=0.015416371832078802, ICIR=0.10174623868044465\n",
      "lh_stdDiff IC: mean=0.0016767165795684676, std=0.015500684773734875, ICIR=0.10817048433947762\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Rank IC 测试\n",
    "def rank_ic(factor_col, return_col):\n",
    "    \"\"\"计算 Rank IC，即因子值与未来收益率的 Spearman 相关系数\"\"\"\n",
    "    ic_values = []\n",
    "    for date, group in merged_data.groupby('date'):\n",
    "        # 只在有超过1个数据点的情况下计算 Spearman 相关系数\n",
    "        if len(group) > 1:\n",
    "            ic_value, _ = spearmanr(group[factor_col], group[return_col])\n",
    "            ic_values.append(ic_value)\n",
    "    # 如果没有有效数据点，返回 NaN\n",
    "    if len(ic_values) == 0:\n",
    "        return np.nan, np.nan\n",
    "    return np.mean(ic_values), np.std(ic_values)\n",
    "\n",
    "# IC 计算\n",
    "ic_lh_rtnDiff_mean, ic_lh_rtnDiff_std = rank_ic('lh_rtnDiff', 'return')\n",
    "ic_lh_volDiff_mean, ic_lh_volDiff_std = rank_ic('lh_volDiff', 'return')\n",
    "ic_lh_stdDiff_mean, ic_lh_stdDiff_std = rank_ic('lh_stdDiff', 'return')\n",
    "\n",
    "# 计算 ICIR (IC mean / IC std)\n",
    "icir_lh_rtnDiff = ic_lh_rtnDiff_mean / ic_lh_rtnDiff_std if ic_lh_rtnDiff_std != 0 else np.nan\n",
    "icir_lh_volDiff = ic_lh_volDiff_mean / ic_lh_volDiff_std if ic_lh_volDiff_std != 0 else np.nan\n",
    "icir_lh_stdDiff = ic_lh_stdDiff_mean / ic_lh_stdDiff_std if ic_lh_stdDiff_std != 0 else np.nan\n",
    "\n",
    "# 显示 Rank IC 结果\n",
    "print(f\"lh_rtnDiff IC: mean={ic_lh_rtnDiff_mean}, std={ic_lh_rtnDiff_std}, ICIR={icir_lh_rtnDiff}\")\n",
    "print(f\"lh_volDiff IC: mean={ic_lh_volDiff_mean}, std={ic_lh_volDiff_std}, ICIR={icir_lh_volDiff}\")\n",
    "print(f\"lh_stdDiff IC: mean={ic_lh_stdDiff_mean}, std={ic_lh_stdDiff_std}, ICIR={icir_lh_stdDiff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh_rtnDiff: 年化收益率=-0.0017817508790120271, 年化波动率=0.0013687703174053978, 夏普比率=-1.3017164796424454, 最大回撤=-0.0003744639212557424\n",
      "lh_volDiff: 年化收益率=-0.0017329076959887244, 年化波动率=0.0016190383263825815, 夏普比率=-1.0703314849010162, 最大回撤=-0.0003921990370828741\n",
      "lh_stdDiff: 年化收益率=-0.0030163476082950965, 年化波动率=0.001660666464972306, 夏普比率=-1.8163476362758963, 最大回撤=-0.0004623263533109667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 多空组合回测\n",
    "def long_short_test(factor_col):\n",
    "    \"\"\"多空组合回测，买入因子值最高的30%股票，卖出因子值最低的30%股票\"\"\"\n",
    "    results = []\n",
    "    for date, group in merged_data.groupby('date'):\n",
    "        # 确保分组内有足够的数据点，最小数量需要是3个（1个多头，1个空头，1个剩余）\n",
    "        if len(group) > 3:\n",
    "            # 将 'return' 列和相关因子列转换为 float 类型，确保兼容\n",
    "            group['return'] = group['return'].astype(float)\n",
    "            group[factor_col] = group[factor_col].astype(float)\n",
    "            \n",
    "            # 按因子值排序\n",
    "            group = group.sort_values(by=factor_col)\n",
    "            long_portfolio = group.iloc[-int(len(group) * 0.3):]  # 拿到最高30%的因子值\n",
    "            short_portfolio = group.iloc[:int(len(group) * 0.3)]  # 拿到最低30%的因子值\n",
    "            \n",
    "            # 计算多头、空头和多空组合收益率\n",
    "            if len(long_portfolio) > 0 and len(short_portfolio) > 0:\n",
    "                long_return = long_portfolio['return'].mean()\n",
    "                short_return = short_portfolio['return'].mean()\n",
    "                long_short_return = long_return - short_return\n",
    "                results.append(long_short_return)\n",
    "            else:\n",
    "                # 如果没有足够的多头或空头组合\n",
    "                results.append(np.nan)\n",
    "        else:\n",
    "            # 如果样本数不足，则跳过\n",
    "            results.append(np.nan)\n",
    "    \n",
    "    # 如果没有有效数据点，返回 NaN\n",
    "    if len(results) == 0 or all(np.isnan(results)):\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    # 转换为 DataFrame 并计算年化收益率、波动率、夏普比率等指标\n",
    "    results_df = pd.DataFrame(results, columns=['long_short_return']).dropna()\n",
    "    if len(results_df) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    annual_return = results_df['long_short_return'].mean() * 252\n",
    "    annual_volatility = results_df['long_short_return'].std() * np.sqrt(252)\n",
    "    sharpe_ratio = annual_return / annual_volatility if annual_volatility != 0 else np.nan\n",
    "    max_drawdown = results_df['long_short_return'].min()\n",
    "    \n",
    "    return annual_return, annual_volatility, sharpe_ratio, max_drawdown\n",
    "\n",
    "# 计算每个因子的多空组合表现\n",
    "annual_return_rtnDiff, annual_vol_rtnDiff, sharpe_rtnDiff, max_drawdown_rtnDiff = long_short_test('lh_rtnDiff')\n",
    "annual_return_volDiff, annual_vol_volDiff, sharpe_volDiff, max_drawdown_volDiff = long_short_test('lh_volDiff')\n",
    "annual_return_stdDiff, annual_vol_stdDiff, sharpe_stdDiff, max_drawdown_stdDiff = long_short_test('lh_stdDiff')\n",
    "\n",
    "# 显示多空组合测试结果\n",
    "print(f\"lh_rtnDiff: 年化收益率={annual_return_rtnDiff}, 年化波动率={annual_vol_rtnDiff}, 夏普比率={sharpe_rtnDiff}, 最大回撤={max_drawdown_rtnDiff}\")\n",
    "print(f\"lh_volDiff: 年化收益率={annual_return_volDiff}, 年化波动率={annual_vol_volDiff}, 夏普比率={sharpe_volDiff}, 最大回撤={max_drawdown_volDiff}\")\n",
    "print(f\"lh_stdDiff: 年化收益率={annual_return_stdDiff}, 年化波动率={annual_vol_stdDiff}, 夏普比率={sharpe_stdDiff}, 最大回撤={max_drawdown_stdDiff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 日内高价/低价序列计算：\n",
    "\n",
    "\t•\t你需要先通过分钟数据，分别计算出日内每分钟的最高价和最低价序列。\n",
    "\t•\t然后，针对高价和低价分别计算排名百分位，并进行15分钟的滑动窗口累计排名。\n",
    "\n",
    "2. 高低价时间点的确定：\n",
    "\n",
    "\t•\t对于每一天的分钟数据，找到排名最高的高价时点和排名最低的低价时点。\n",
    "\n",
    "3. 构建因子：\n",
    "\n",
    "\t•\t根据高价时点和低价时点的成交量、波动率等信息，构建不同的差异因子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设 `data` 是日内分钟级别的数据，包含每只股票的'open', 'high', 'low', 'close', 'volume'等信息。\n",
    "# 确保 'date' 列是 datetime 类型，且包含交易的具体分钟\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# 确保数值列为 float 类型，避免 Decimal 和 float 类型混用\n",
    "data['open'] = data['open'].astype(float)\n",
    "data['high'] = data['high'].astype(float)\n",
    "data['low'] = data['low'].astype(float)\n",
    "data['volume'] = data['volume'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 计算每分钟高低价的排名百分位\n",
    "def pct_rank(s):\n",
    "    return s.rank(pct=True)\n",
    "\n",
    "# 对每只股票的每个交易日计算高价、低价的排名\n",
    "data['high_rank'] = data.groupby(['stkcd', data['date'].dt.date])['high'].transform(pct_rank)\n",
    "data['low_rank'] = data.groupby(['stkcd', data['date'].dt.date])['low'].transform(pct_rank)\n",
    "\n",
    "# Step 2: 计算15分钟的滑动窗口的累加高低价排名\n",
    "data['highRank_sum'] = data.groupby('stkcd')['high_rank'].transform(lambda x: x.rolling(window=15, min_periods=1).sum())\n",
    "data['lowRank_sum'] = data.groupby('stkcd')['low_rank'].transform(lambda x: x.rolling(window=15, min_periods=1).sum())\n",
    "\n",
    "# Step 3: 确定高价/低价的时点（找到累计排名最大的高价和最小的低价的时刻）\n",
    "data['high_dt'] = data.groupby(['stkcd', data['date'].dt.date])['highRank_sum'].transform(np.argmax)\n",
    "data['low_dt'] = data.groupby(['stkcd', data['date'].dt.date])['lowRank_sum'].transform(np.argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'stkcd', 'open', 'high', 'low', 'close', 'volume', 'money',\n",
      "       'session', 'hour', 'hour_segment', 'price_diff', 'time_period',\n",
      "       'return', 'high_rank', 'low_rank', 'highRank_sum', 'lowRank_sum',\n",
      "       'high_dt', 'low_dt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stkcd       date  diff_std  diff_vol\n",
      "0  000001.XSHE 2022-12-01  0.044682       NaN\n",
      "1  000001.XSHE 2022-12-01  0.044682       NaN\n",
      "2  000001.XSHE 2022-12-01  0.044682       NaN\n",
      "3  000001.XSHE 2022-12-01  0.044682       NaN\n",
      "4  000001.XSHE 2022-12-01  0.044682       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设你的数据 DataFrame 是 'data'\n",
    "data['date'] = pd.to_datetime(data['date'])  # 确保 'date' 列为 datetime 类型\n",
    "data['open'] = data['open'].astype(float)    # 转换数值列为 float\n",
    "data['high'] = data['high'].astype(float)\n",
    "data['low'] = data['low'].astype(float)\n",
    "data['volume'] = data['volume'].astype(float)\n",
    "\n",
    "# 定义计算波动率差异和成交量差异的函数\n",
    "def calc_diff_std_vol(group):\n",
    "    # 计算波动率差异 (高价-低价)/开盘价\n",
    "    diff_std = (group['high'].max() - group['low'].min()) / group['open'].mean()\n",
    "    \n",
    "    # 计算成交量差异，避免除以零的情况\n",
    "    vol_min = group['volume'].min()\n",
    "    if vol_min == 0:\n",
    "        diff_vol = np.nan  # 如果最小值为0，则设为 NaN\n",
    "    else:\n",
    "        diff_vol = group['volume'].max() / vol_min\n",
    "    \n",
    "    return pd.Series({'diff_std': diff_std, 'diff_vol': diff_vol})\n",
    "\n",
    "# 按股票代码和日期分组，计算每组的波动率和成交量差异\n",
    "grouped_data = data.groupby(['stkcd', data['date'].dt.date]).apply(calc_diff_std_vol).reset_index()\n",
    "\n",
    "# 确保 'date' 列的类型一致\n",
    "grouped_data['date'] = pd.to_datetime(grouped_data['date'])  # 将 'grouped_data' 中的 'date' 列转换为 datetime 类型\n",
    "\n",
    "# 合并计算结果回到原始数据中\n",
    "merged_data = pd.merge(data, grouped_data, on=['stkcd', 'date'], how='left')\n",
    "\n",
    "# 检查结果\n",
    "print(merged_data[['stkcd', 'date', 'diff_std', 'diff_vol']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stkcd        date      \n",
      "000001.XSHE  2022-12-01    0.0\n",
      "             2022-12-02    0.0\n",
      "             2022-12-05    0.0\n",
      "             2022-12-06    0.0\n",
      "             2022-12-07    0.0\n",
      "                          ... \n",
      "000010.XSHE  2024-08-16    0.0\n",
      "             2024-08-19    0.0\n",
      "             2024-08-20    0.0\n",
      "             2024-08-21    0.0\n",
      "             2024-08-22    0.0\n",
      "Name: volume, Length: 3781, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 查看每组的最小成交量是否为 0\n",
    "volume_min_check = data.groupby(['stkcd', data['date'].dt.date])['volume'].min()\n",
    "print(volume_min_check[volume_min_check == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stkcd       date  diff_std  diff_vol\n",
      "0  000001.XSHE 2022-12-01  0.044682       0.0\n",
      "1  000001.XSHE 2022-12-01  0.044682       0.0\n",
      "2  000001.XSHE 2022-12-01  0.044682       0.0\n",
      "3  000001.XSHE 2022-12-01  0.044682       0.0\n",
      "4  000001.XSHE 2022-12-01  0.044682       0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设你的数据 DataFrame 是 'data'\n",
    "data['date'] = pd.to_datetime(data['date'])  # 确保 'date' 列为 datetime 类型\n",
    "data['open'] = data['open'].astype(float)    # 转换数值列为 float\n",
    "data['high'] = data['high'].astype(float)\n",
    "data['low'] = data['low'].astype(float)\n",
    "data['volume'] = data['volume'].astype(float)\n",
    "\n",
    "# 定义计算波动率差异和成交量差异的函数\n",
    "def calc_diff_std_vol(group):\n",
    "    # 计算波动率差异 (高价-低价)/开盘价\n",
    "    diff_std = (group['high'].max() - group['low'].min()) / group['open'].mean()\n",
    "    \n",
    "    # 计算成交量差异，避免除以零的情况\n",
    "    vol_min = group['volume'].min()\n",
    "    if vol_min == 0:\n",
    "        diff_vol = 0  # 如果最小值为0，则将成交量差异设为0\n",
    "    else:\n",
    "        diff_vol = group['volume'].max() / vol_min\n",
    "    \n",
    "    return pd.Series({'diff_std': diff_std, 'diff_vol': diff_vol})\n",
    "\n",
    "# 按股票代码和日期分组，计算每组的波动率和成交量差异\n",
    "grouped_data = data.groupby(['stkcd', data['date'].dt.date]).apply(calc_diff_std_vol).reset_index()\n",
    "\n",
    "# 确保 'date' 列的类型一致\n",
    "grouped_data['date'] = pd.to_datetime(grouped_data['date'])  # 将 'grouped_data' 中的 'date' 列转换为 datetime 类型\n",
    "\n",
    "# 合并计算结果回到原始数据中\n",
    "merged_data = pd.merge(data, grouped_data, on=['stkcd', 'date'], how='left')\n",
    "\n",
    "# 检查结果\n",
    "print(merged_data[['stkcd', 'date', 'diff_std', 'diff_vol']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要对日内股价分域特征基础因子进行因子表现的评估和测试。这可以通过如下几个步骤实现：\n",
    "\n",
    "\t1.\t因子IC计算：\n",
    "\t•\t计算每个因子的IC均值、IC标准差和ICIR。\n",
    "\t•\tIC（Information Coefficient）表示因子对股票价格预测的能力，计算方式通常为因子值与未来收益之间的相关系数。\n",
    "\t2.\t因子多空组合测试：\n",
    "\t•\t对不同因子进行多空组合测试，计算多空组合收益率、年化波动率、夏普比率、最大回撤等指标。\n",
    "\n",
    "实现步骤：\n",
    "\n",
    "第一步：IC计算\n",
    "\n",
    "我们可以使用 Spearman 相关系数来计算每个因子的IC。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 'close' 是收盘价，我们计算未来1天的收益率\n",
    "data['future_return'] = data.groupby('stkcd')['close'].shift(-1) / data['close'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>session</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>time_period</th>\n",
       "      <th>return</th>\n",
       "      <th>high_rank</th>\n",
       "      <th>low_rank</th>\n",
       "      <th>highRank_sum</th>\n",
       "      <th>lowRank_sum</th>\n",
       "      <th>high_dt</th>\n",
       "      <th>low_dt</th>\n",
       "      <th>future_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>705600</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1657.91</td>\n",
       "      <td>1691.37</td>\n",
       "      <td>1656.67</td>\n",
       "      <td>1687.6500000000</td>\n",
       "      <td>160780.0</td>\n",
       "      <td>268431460.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.6800000000</td>\n",
       "      <td>morning_half_hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806400</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1657.91</td>\n",
       "      <td>1691.37</td>\n",
       "      <td>1656.67</td>\n",
       "      <td>1687.6500000000</td>\n",
       "      <td>160780.0</td>\n",
       "      <td>268431460.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.6800000000</td>\n",
       "      <td>morning_half_hour</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>1.989583</td>\n",
       "      <td>1.956250</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>-0.0117500666607412674428939650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705601</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1685.17</td>\n",
       "      <td>1692.61</td>\n",
       "      <td>1666.59</td>\n",
       "      <td>1667.8200000000</td>\n",
       "      <td>65530.0</td>\n",
       "      <td>109918445.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.6800000000</td>\n",
       "      <td>morning_half_hour</td>\n",
       "      <td>-0.0117500666607412674428939650</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>2.988542</td>\n",
       "      <td>2.953125</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806401</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1685.17</td>\n",
       "      <td>1692.61</td>\n",
       "      <td>1666.59</td>\n",
       "      <td>1667.8200000000</td>\n",
       "      <td>65530.0</td>\n",
       "      <td>109918445.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.6800000000</td>\n",
       "      <td>morning_half_hour</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>3.987500</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>-0.0007374896571572471849480160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705602</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>000001.XSHE</td>\n",
       "      <td>1667.82</td>\n",
       "      <td>1670.30</td>\n",
       "      <td>1666.59</td>\n",
       "      <td>1666.5900000000</td>\n",
       "      <td>42739.0</td>\n",
       "      <td>71314814.0000000000</td>\n",
       "      <td>morning</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.6800000000</td>\n",
       "      <td>morning_half_hour</td>\n",
       "      <td>-0.0007374896571572471849480160</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>4.978125</td>\n",
       "      <td>4.946875</td>\n",
       "      <td>14</td>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403195</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>16979.0</td>\n",
       "      <td>379664.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "      <td>-0.006231</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403196</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>8756.0</td>\n",
       "      <td>196265.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403197</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403198</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>0.00627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403199</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>000010.XSHE</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>22.47</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>94809.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>afternoon_half_hour</td>\n",
       "      <td>0.00627</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>33</td>\n",
       "      <td>231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008240 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        stkcd     open     high      low            close  \\\n",
       "705600 2022-12-01  000001.XSHE  1657.91  1691.37  1656.67  1687.6500000000   \n",
       "806400 2022-12-01  000001.XSHE  1657.91  1691.37  1656.67  1687.6500000000   \n",
       "705601 2022-12-01  000001.XSHE  1685.17  1692.61  1666.59  1667.8200000000   \n",
       "806401 2022-12-01  000001.XSHE  1685.17  1692.61  1666.59  1667.8200000000   \n",
       "705602 2022-12-01  000001.XSHE  1667.82  1670.30  1666.59  1666.5900000000   \n",
       "...           ...          ...      ...      ...      ...              ...   \n",
       "403195 2024-08-22  000010.XSHE    22.47    22.47    22.33            22.33   \n",
       "403196 2024-08-22  000010.XSHE    22.47    22.47    22.33            22.33   \n",
       "403197 2024-08-22  000010.XSHE    22.33    22.33    22.33            22.33   \n",
       "403198 2024-08-22  000010.XSHE    22.33    22.33    22.33            22.33   \n",
       "403199 2024-08-22  000010.XSHE    22.47    22.47    22.47            22.47   \n",
       "\n",
       "          volume                 money    session  hour  ...       price_diff  \\\n",
       "705600  160780.0  268431460.0000000000    morning     9  ...  -232.6800000000   \n",
       "806400  160780.0  268431460.0000000000    morning     9  ...  -232.6800000000   \n",
       "705601   65530.0  109918445.0000000000    morning     9  ...  -232.6800000000   \n",
       "806401   65530.0  109918445.0000000000    morning     9  ...  -232.6800000000   \n",
       "705602   42739.0   71314814.0000000000    morning     9  ...  -232.6800000000   \n",
       "...          ...                   ...        ...   ...  ...              ...   \n",
       "403195   16979.0              379664.0  afternoon    14  ...           -21.93   \n",
       "403196    8756.0              196265.0  afternoon    14  ...           -21.93   \n",
       "403197       0.0                   0.0  afternoon    14  ...           -21.93   \n",
       "403198       0.0                   0.0  afternoon    14  ...           -21.93   \n",
       "403199    4220.0               94809.0  afternoon    15  ...           -21.93   \n",
       "\n",
       "                time_period                           return high_rank  \\\n",
       "705600    morning_half_hour                              NaN  0.994792   \n",
       "806400    morning_half_hour                                0  0.994792   \n",
       "705601    morning_half_hour  -0.0117500666607412674428939650  0.998958   \n",
       "806401    morning_half_hour                                0  0.998958   \n",
       "705602    morning_half_hour  -0.0007374896571572471849480160  0.990625   \n",
       "...                     ...                              ...       ...   \n",
       "403195  afternoon_half_hour                        -0.006231  0.120833   \n",
       "403196  afternoon_half_hour                              0.0  0.120833   \n",
       "403197  afternoon_half_hour                              0.0  0.008333   \n",
       "403198  afternoon_half_hour                              0.0  0.008333   \n",
       "403199  afternoon_half_hour                          0.00627  0.120833   \n",
       "\n",
       "        low_rank  highRank_sum  lowRank_sum  high_dt  low_dt  \\\n",
       "705600  0.978125      0.994792     0.978125       14     477   \n",
       "806400  0.978125      1.989583     1.956250       14     477   \n",
       "705601  0.996875      2.988542     2.953125       14     477   \n",
       "806401  0.996875      3.987500     3.950000       14     477   \n",
       "705602  0.996875      4.978125     4.946875       14     477   \n",
       "...          ...           ...          ...      ...     ...   \n",
       "403195  0.058333      1.812500     1.029167       33     231   \n",
       "403196  0.058333      1.812500     1.029167       33     231   \n",
       "403197  0.058333      1.700000     1.029167       33     231   \n",
       "403198  0.058333      1.587500     1.029167       33     231   \n",
       "403199  0.212500      1.587500     1.029167       33     231   \n",
       "\n",
       "                          future_return  \n",
       "705600                                0  \n",
       "806400  -0.0117500666607412674428939650  \n",
       "705601                                0  \n",
       "806401  -0.0007374896571572471849480160  \n",
       "705602                                0  \n",
       "...                                 ...  \n",
       "403195                              0.0  \n",
       "403196                              0.0  \n",
       "403197                              0.0  \n",
       "403198                          0.00627  \n",
       "403199                              NaN  \n",
       "\n",
       "[1008240 rows x 21 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要保存结果到文件，例如Mac桌面：\n",
    "data.to_csv('/Users/zhangrui/Desktop/factor_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stkcd       date            close                    future_return\n",
      "0  000001.XSHE 2022-12-01  1687.6500000000                                0\n",
      "1  000001.XSHE 2022-12-01  1687.6500000000  -0.0117500666607412674428939650\n",
      "2  000001.XSHE 2022-12-01  1667.8200000000                                0\n",
      "3  000001.XSHE 2022-12-01  1667.8200000000  -0.0007374896571572471849480160\n",
      "4  000001.XSHE 2022-12-01  1666.5900000000                                0\n"
     ]
    }
   ],
   "source": [
    "# 使用收盘价生成未来一天的收益率\n",
    "merged_data['future_return'] = merged_data.groupby('stkcd')['close'].shift(-1) / merged_data['close'] - 1\n",
    "\n",
    "# 检查 'future_return' 列是否生成正确\n",
    "print(merged_data[['stkcd', 'date', 'close', 'future_return']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_std IC: nan\n",
      "diff_vol IC: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangrui/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# 定义计算IC的函数\n",
    "def calc_ic(merged_data, factor_name):\n",
    "    # 计算IC，使用Spearman相关系数\n",
    "    ic, _ = spearmanr(merged_data[factor_name], merged_data['future_return'])\n",
    "    return ic\n",
    "\n",
    "# 计算 diff_std、diff_vol 的IC\n",
    "ic_diff_std = calc_ic(merged_data, 'diff_std')\n",
    "ic_diff_vol = calc_ic(merged_data, 'diff_vol')\n",
    "\n",
    "# 打印结果\n",
    "print(f\"diff_std IC: {ic_diff_std}\")\n",
    "print(f\"diff_vol IC: {ic_diff_vol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_std 值分布:\n",
      "count    988800.000000\n",
      "mean          0.031622\n",
      "std           0.023306\n",
      "min           0.000000\n",
      "25%           0.016854\n",
      "50%           0.024617\n",
      "75%           0.038806\n",
      "max           0.206526\n",
      "Name: diff_std, dtype: float64\n",
      "diff_vol 值分布:\n",
      "count    1008240.0\n",
      "mean           0.0\n",
      "std            0.0\n",
      "min            0.0\n",
      "25%            0.0\n",
      "50%            0.0\n",
      "75%            0.0\n",
      "max            0.0\n",
      "Name: diff_vol, dtype: float64\n",
      "diff_std 是否有 NaN 值: 19440\n",
      "diff_vol 是否有 NaN 值: 0\n"
     ]
    }
   ],
   "source": [
    "# 检查 diff_std 和 diff_vol 是否包含恒定值或 NaN 值\n",
    "print(\"diff_std 值分布:\")\n",
    "print(merged_data['diff_std'].describe())\n",
    "\n",
    "print(\"diff_vol 值分布:\")\n",
    "print(merged_data['diff_vol'].describe())\n",
    "\n",
    "# 检查是否有 NaN 值\n",
    "print(\"diff_std 是否有 NaN 值:\", merged_data['diff_std'].isna().sum())\n",
    "print(\"diff_vol 是否有 NaN 值:\", merged_data['diff_vol'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangrui/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_std IC: nan\n",
      "diff_vol IC: nan\n",
      "diff_std IC均值: -0.007524932532888245, IC标准差: 0.01791000367472435, ICIR: -0.4201524840281229\n",
      "diff_vol IC均值: nan, IC标准差: nan, ICIR: nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'decimal.Decimal' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff_vol IC均值: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mic_mean_vol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, IC标准差: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mic_std_vol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ICIR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mic_ir_vol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 分别计算 diff_std、diff_vol 的多空组合收益率和波动率\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m annual_return_std, vol_std \u001b[38;5;241m=\u001b[39m \u001b[43mlong_short_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiff_std\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m annual_return_vol, vol_vol \u001b[38;5;241m=\u001b[39m long_short_strategy(merged_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_vol\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 打印结果\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[98], line 8\u001b[0m, in \u001b[0;36mlong_short_strategy\u001b[0;34m(merged_data, factor_name, quantile)\u001b[0m\n\u001b[1;32m      5\u001b[0m short \u001b[38;5;241m=\u001b[39m merged_data[merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(quantile)]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 多头和空头组合的平均收益率\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m long_return \u001b[38;5;241m=\u001b[39m \u001b[43mlong\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfuture_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m short_return \u001b[38;5;241m=\u001b[39m short[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuture_return\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 多空组合的年化收益率和年化波动率\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11540\u001b[0m     _num_doc,\n\u001b[1;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11555\u001b[0m ):\n\u001b[0;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4668\u001b[0m     )\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'decimal.Decimal' and 'float'"
     ]
    }
   ],
   "source": [
    "# 计算 diff_std、diff_vol 的IC\n",
    "ic_diff_std = calc_ic(merged_data, 'diff_std')\n",
    "ic_diff_vol = calc_ic(merged_data, 'diff_vol')\n",
    "\n",
    "# 打印结果\n",
    "print(f\"diff_std IC: {ic_diff_std}\")\n",
    "print(f\"diff_vol IC: {ic_diff_vol}\")\n",
    "\n",
    "# 分别计算 diff_std、diff_vol 的IC统计结果\n",
    "ic_mean_std, ic_std_std, ic_ir_std = calc_ic_stats(merged_data, 'diff_std')\n",
    "ic_mean_vol, ic_std_vol, ic_ir_vol = calc_ic_stats(merged_data, 'diff_vol')\n",
    "\n",
    "# 打印统计结果\n",
    "print(f\"diff_std IC均值: {ic_mean_std}, IC标准差: {ic_std_std}, ICIR: {ic_ir_std}\")\n",
    "print(f\"diff_vol IC均值: {ic_mean_vol}, IC标准差: {ic_std_vol}, ICIR: {ic_ir_vol}\")\n",
    "\n",
    "# 分别计算 diff_std、diff_vol 的多空组合收益率和波动率\n",
    "annual_return_std, vol_std = long_short_strategy(merged_data, 'diff_std')\n",
    "annual_return_vol, vol_vol = long_short_strategy(merged_data, 'diff_vol')\n",
    "\n",
    "# 打印结果\n",
    "print(f\"diff_std 年化收益率: {annual_return_std}, 年化波动率: {vol_std}\")\n",
    "print(f\"diff_vol 年化收益率: {annual_return_vol}, 年化波动率: {vol_vol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步：IC的统计分析\n",
    "\n",
    "为了获得 IC 的均值和标准差，可以将上述计算 IC 的过程应用于一段时间内的数据，计算多个时间段的IC并统计结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'diff_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'diff_idx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ic_mean, ic_std, ic_ir\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 分别计算 diff_idx, diff_std, diff_vol 的IC统计结果\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m ic_mean_idx, ic_std_idx, ic_ir_idx \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_ic_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiff_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m ic_mean_std, ic_std_std, ic_ir_std \u001b[38;5;241m=\u001b[39m calc_ic_stats(merged_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_std\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ic_mean_vol, ic_std_vol, ic_ir_vol \u001b[38;5;241m=\u001b[39m calc_ic_stats(merged_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_vol\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m, in \u001b[0;36mcalc_ic_stats\u001b[0;34m(merged_data, factor_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_ic_stats\u001b[39m(merged_data, factor_name):\n\u001b[0;32m----> 2\u001b[0m     ic_values \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_ic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     ic_mean \u001b[38;5;241m=\u001b[39m ic_values\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m     ic_std \u001b[38;5;241m=\u001b[39m ic_values\u001b[38;5;241m.\u001b[39mstd()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m, in \u001b[0;36mcalc_ic_stats.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_ic_stats\u001b[39m(merged_data, factor_name):\n\u001b[0;32m----> 2\u001b[0m     ic_values \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcalc_ic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m     ic_mean \u001b[38;5;241m=\u001b[39m ic_values\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m     ic_std \u001b[38;5;241m=\u001b[39m ic_values\u001b[38;5;241m.\u001b[39mstd()\n",
      "Cell \u001b[0;32mIn[96], line 8\u001b[0m, in \u001b[0;36mcalc_ic\u001b[0;34m(merged_data, factor_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_ic\u001b[39m(merged_data, factor_name):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# 计算IC，使用Spearman相关系数\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     ic, _ \u001b[38;5;241m=\u001b[39m spearmanr(\u001b[43mmerged_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfactor_name\u001b[49m\u001b[43m]\u001b[49m, merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuture_return\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ic\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'diff_idx'"
     ]
    }
   ],
   "source": [
    "def calc_ic_stats(merged_data, factor_name):\n",
    "    ic_values = merged_data.groupby('date').apply(lambda x: calc_ic(x, factor_name))\n",
    "    ic_mean = ic_values.mean()\n",
    "    ic_std = ic_values.std()\n",
    "    ic_ir = ic_mean / ic_std  # 计算ICIR\n",
    "    return ic_mean, ic_std, ic_ir\n",
    "\n",
    "# 分别计算 diff_idx, diff_std, diff_vol 的IC统计结果\n",
    "ic_mean_idx, ic_std_idx, ic_ir_idx = calc_ic_stats(merged_data, 'diff_idx')\n",
    "ic_mean_std, ic_std_std, ic_ir_std = calc_ic_stats(merged_data, 'diff_std')\n",
    "ic_mean_vol, ic_std_vol, ic_ir_vol = calc_ic_stats(merged_data, 'diff_vol')\n",
    "\n",
    "# 打印统计结果\n",
    "print(f\"diff_idx IC均值: {ic_mean_idx}, IC标准差: {ic_std_idx}, ICIR: {ic_ir_idx}\")\n",
    "print(f\"diff_std IC均值: {ic_mean_std}, IC标准差: {ic_std_std}, ICIR: {ic_ir_std}\")\n",
    "print(f\"diff_vol IC均值: {ic_mean_vol}, IC标准差: {ic_std_vol}, ICIR: {ic_ir_vol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三步：多空组合测试\n",
    "\n",
    "为每个因子构建多空组合，计算每个因子的多空收益率和相关的金融指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'diff_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'diff_idx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m annual_return, volatility\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 分别计算 diff_idx、diff_std、diff_vol 的多空组合收益率和波动率\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m annual_return_idx, vol_idx \u001b[38;5;241m=\u001b[39m \u001b[43mlong_short_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiff_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m annual_return_std, vol_std \u001b[38;5;241m=\u001b[39m long_short_strategy(merged_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_std\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m annual_return_vol, vol_vol \u001b[38;5;241m=\u001b[39m long_short_strategy(merged_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_vol\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[98], line 3\u001b[0m, in \u001b[0;36mlong_short_strategy\u001b[0;34m(merged_data, factor_name, quantile)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlong_short_strategy\u001b[39m(merged_data, factor_name, quantile\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 计算每个因子的多空组合收益率\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfactor_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrank()\n\u001b[1;32m      4\u001b[0m     long \u001b[38;5;241m=\u001b[39m merged_data[merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m quantile)]\n\u001b[1;32m      5\u001b[0m     short \u001b[38;5;241m=\u001b[39m merged_data[merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(quantile)]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'diff_idx'"
     ]
    }
   ],
   "source": [
    "def long_short_strategy(merged_data, factor_name, quantile=0.2):\n",
    "    # 计算每个因子的多空组合收益率\n",
    "    merged_data['rank'] = merged_data[factor_name].rank()\n",
    "    long = merged_data[merged_data['rank'] >= merged_data['rank'].quantile(1 - quantile)]\n",
    "    short = merged_data[merged_data['rank'] <= merged_data['rank'].quantile(quantile)]\n",
    "    \n",
    "    # 多头和空头组合的平均收益率\n",
    "    long_return = long['future_return'].mean()\n",
    "    short_return = short['future_return'].mean()\n",
    "    \n",
    "    # 多空组合的年化收益率和年化波动率\n",
    "    annual_return = (long_return - short_return) * 252  # 假设一年有252个交易日\n",
    "    volatility = merged_data['future_return'].std() * np.sqrt(252)\n",
    "    \n",
    "    return annual_return, volatility\n",
    "\n",
    "# 分别计算 diff_idx、diff_std、diff_vol 的多空组合收益率和波动率\n",
    "annual_return_idx, vol_idx = long_short_strategy(merged_data, 'diff_idx')\n",
    "annual_return_std, vol_std = long_short_strategy(merged_data, 'diff_std')\n",
    "annual_return_vol, vol_vol = long_short_strategy(merged_data, 'diff_vol')\n",
    "\n",
    "# 打印结果\n",
    "print(f\"diff_idx 年化收益率: {annual_return_idx}, 年化波动率: {vol_idx}\")\n",
    "print(f\"diff_std 年化收益率: {annual_return_std}, 年化波动率: {vol_std}\")\n",
    "print(f\"diff_vol 年化收益率: {annual_return_vol}, 年化波动率: {vol_vol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "\n",
    "\t•\tIC计算 用于衡量因子的预测能力，ICIR越高，因子的表现越好。\n",
    "\t•\t多空组合测试 通过构建因子的多空组合，评估其收益率和波动性等指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 自身显著性因子构建\n",
    "\n",
    "基于显著性理论，从股票自身的日内交易特征出发，构建特异性因子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_intraday_volatility\u001b[39m(df):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpct_change())\n\u001b[0;32m----> 5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintraday_volatility\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msymbol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(calc_intraday_volatility)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 构建显著性因子\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_significance\u001b[39m(df):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8255\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8258\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/suishi/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'symbol'"
     ]
    }
   ],
   "source": [
    "# 分析显著性：计算每个时间段的波动率和成交量特征\n",
    "def calc_intraday_volatility(df):\n",
    "    return np.std(df['close'].pct_change())\n",
    "\n",
    "data['intraday_volatility'] = data.groupby('symbol').apply(calc_intraday_volatility)\n",
    "\n",
    "# 构建显著性因子\n",
    "def calc_significance(df):\n",
    "    vol = df['intraday_volatility'].mean()\n",
    "    volume = df['volume'].mean()\n",
    "    return vol * volume  # 简化的显著性公式，具体需参考研报中的显著性算法\n",
    "\n",
    "data['significance'] = data.groupby('symbol').apply(calc_significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 股票间相似性与“同伴”显著性因子构建\n",
    "\n",
    "使用日内量价数据进行股票间的成对相似性计算，刻画“同伴”显著性因子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建股票间的相似性矩阵\n",
    "def calc_pairwise_similarity(df1, df2):\n",
    "    return np.corrcoef(df1['close'], df2['close'])[0, 1]\n",
    "\n",
    "# 基于相似性计算同伴显著性因子\n",
    "symbols = data['symbol'].unique()\n",
    "similarity_matrix = pd.DataFrame(index=symbols, columns=symbols)\n",
    "\n",
    "for sym1 in symbols:\n",
    "    for sym2 in symbols:\n",
    "        similarity_matrix.loc[sym1, sym2] = calc_pairwise_similarity(data[data['symbol'] == sym1], data[data['symbol'] == sym2])\n",
    "\n",
    "# 构建“同伴”显著性因子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 因子回测与表现评估\n",
    "\n",
    "根据研报中的回测规则，对构建的因子进行回测，并计算回测指标，如IC、夏普比率、年化收益率等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回测因子表现\n",
    "def backtest_factor(df, factor_column):\n",
    "    # 示例回测策略：T+1买入因子值最高的股票\n",
    "    long_positions = df.groupby('symbol')[factor_column].shift(1).rank(ascending=False) < 10\n",
    "    returns = df['close'].pct_change().shift(-1)\n",
    "    strategy_returns = (returns * long_positions).mean()\n",
    "    return strategy_returns\n",
    "\n",
    "# 测试因子的表现\n",
    "factor_performance = backtest_factor(data, 'significance')\n",
    "print(f\"因子表现: {factor_performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 风险分析与提示\n",
    "\n",
    "考虑市场环境变化对因子表现的影响，并引入风险提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析模型在不同市场环境下的表现\n",
    "def analyze_risk(df, factor_column):\n",
    "    # 比如分牛市、熊市环境分析因子表现\n",
    "    bull_market = df['market_trend'] == 'bull'\n",
    "    bear_market = df['market_trend'] == 'bear'\n",
    "    \n",
    "    bull_performance = backtest_factor(df[bull_market], factor_column)\n",
    "    bear_performance = backtest_factor(df[bear_market], factor_column)\n",
    "    \n",
    "    print(f\"Bull market performance: {bull_performance}, Bear market performance: {bear_performance}\")\n",
    "\n",
    "analyze_risk(data, 'significance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suishi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
